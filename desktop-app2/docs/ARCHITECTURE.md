# Desktop App2 Architecture

**Technical design document for developers**

---

## System Overview

Desktop App2 is a hybrid Electron + Python application that combines:
- **Electron**: Native desktop wrapper, API key storage, window management
- **Streamlit**: Web UI framework running locally on port 8501
- **App4**: Full unified dashboard codebase (imported from deployment/)
- **ChatGPT**: OpenAI API client for language model integration

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ELECTRON MAIN PROCESS                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  main.js                                            â”‚  â”‚
â”‚  â”‚  - Creates BrowserWindow                            â”‚  â”‚
â”‚  â”‚  - Spawns Python backend (Streamlit)               â”‚  â”‚
â”‚  â”‚  - Waits for http://localhost:8501                 â”‚  â”‚
â”‚  â”‚  - Loads Streamlit in window                       â”‚  â”‚
â”‚  â”‚  - IPC handlers for API keys                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â–²                                â”‚
â”‚                           â”‚ IPC Messages                   â”‚
â”‚                           â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  preload.js (Security Bridge)                      â”‚  â”‚
â”‚  â”‚  - Exposes electronAPI to renderer                â”‚  â”‚
â”‚  â”‚  - Context isolation enabled                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                â”‚
â”‚                           â”‚ HTTP (localhost:8501)          â”‚
â”‚                           â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  BrowserWindow (Renderer)                          â”‚  â”‚
â”‚  â”‚  - Loads Streamlit web UI                         â”‚  â”‚
â”‚  â”‚  - Can call electronAPI (via preload)             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ HTTP Requests
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PYTHON BACKEND (Streamlit)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  app.py (Main Entry Point)                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  API Key Setup Screen                       â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - if not st.session_state.api_key_configuredâ”‚  â”‚
â”‚  â”‚  â”‚  - Prompts for OpenAI key                   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Model selection                           â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  App4 Dashboard                             â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - if api_key_configured                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Renders 4 tabs                           â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Initializes components                   â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                â”‚
â”‚                           â”‚ Imports                        â”‚
â”‚                           â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  chatgpt_integration.py                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  class ChatGPTClient                        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - __init__(api_key, model)                 â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - send_message(msg, temp, max_tokens)      â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - clear_history()                           â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - export_conversation(path)                 â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - add_system_message(prompt)                â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚  Compatible with App4's LLM client interface       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                â”‚
â”‚                           â”‚ Uses                           â”‚
â”‚                           â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  App4 Components (from ../../deployment/)         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  core/pipeline_orchestrator.py              â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Orchestrates 3 stages                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Manages conversations                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - add_turn(), calculate_stage2/3()         â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  ui/chat_view.py, sidebar.py                â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Renders UI components                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Chat history, metrics, controls          â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  app.py (Tab Renderers)                     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - render_tab1_live_chat()                  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - render_tab2_rho_analysis()               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - render_tab3_phi_benchmark()              â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - render_tab4_settings()                   â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                â”‚
â”‚                           â”‚ Uses                           â”‚
â”‚                           â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Shared Modules (from ../../deployment/shared/)   â”‚  â”‚
â”‚  â”‚  - pca_pipeline.py (PCATransformer)                â”‚  â”‚
â”‚  â”‚  - vector_processor.py (Stage 1)                   â”‚  â”‚
â”‚  â”‚  - robustness_calculator.py (Stage 2)              â”‚  â”‚
â”‚  â”‚  - fragility_calculator.py (Stage 3)               â”‚  â”‚
â”‚  â”‚  - visualizations.py (Plots)                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ API Calls
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  OpenAI API      â”‚
                   â”‚  (ChatGPT)       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Details

### 1. Electron Layer

#### main.js

**Responsibilities**:
- Create and manage BrowserWindow
- Launch Python backend (Streamlit)
- Wait for Streamlit server to start
- Load Streamlit UI in window
- Handle IPC messages
- Manage secure storage

**Key Functions**:

```javascript
startPythonBackend()
// Spawns: python -m streamlit run app.py
// Env: OPENAI_API_KEY, ELECTRON_MODE

waitForStreamlit(maxRetries, delay)
// Polls http://localhost:8501 until ready

createWindow()
// Creates BrowserWindow with preload script
// Loads STREAMLIT_URL
```

**IPC Handlers**:

```javascript
ipcMain.handle('store-openai-key', async (event, apiKey))
// Stores API key in encrypted electron-store
// Restarts Python backend with new key

ipcMain.handle('get-openai-key', async ())
// Retrieves stored API key

ipcMain.handle('delete-openai-key', async ())
// Deletes stored API key

ipcMain.handle('store-aws-credentials', async (event, credentials))
// Stores AWS credentials for embeddings

ipcMain.handle('get-aws-credentials', async ())
// Retrieves AWS credentials
```

#### preload.js

**Responsibilities**:
- Exposes secure API to renderer process
- Context isolation bridge

**Exposed API**:

```javascript
window.electronAPI = {
  storeOpenAIKey: (key) => ipcRenderer.invoke('store-openai-key', key),
  getOpenAIKey: () => ipcRenderer.invoke('get-openai-key'),
  deleteOpenAIKey: () => ipcRenderer.invoke('delete-openai-key'),
  checkAPIKey: () => ipcRenderer.invoke('check-api-key'),
  storeAWSCredentials: (creds) => ipcRenderer.invoke('store-aws-credentials', creds),
  getAWSCredentials: () => ipcRenderer.invoke('get-aws-credentials'),
  isElectron: () => true
}
```

---

### 2. Python Backend

#### app.py

**Responsibilities**:
- Main Streamlit entry point
- API key setup screen
- App4 initialization
- Tab rendering coordination

**Flow**:

```python
def main():
    # Check if API key configured
    if not st.session_state.api_key_configured:
        # Check environment (set by Electron)
        if env_key exists:
            auto-configure
        else:
            show_api_key_setup()
            return

    # Initialize App4
    config, orchestrator, llm_client, pca = initialize_app()

    # Create tabs
    tab1, tab2, tab3, tab4 = st.tabs([...])

    # Render tabs (using App4's renderers)
    render_tab1_live_chat(...)
    render_tab2_rho_analysis(...)
    render_tab3_phi_benchmark(...)
    render_tab4_settings(...)
```

**Key Functions**:

```python
show_api_key_setup()
# Displays API key input form
# Model selection dropdown
# Save button â†’ stores in session_state

initialize_app()
# Imports App4 components
# Creates PipelineOrchestrator
# Initializes ChatGPTClient
# Returns (config, orchestrator, llm_client, pca)
```

#### chatgpt_integration.py

**Responsibilities**:
- Wrap OpenAI API
- Match App4's LLM client interface
- Maintain conversation history

**ChatGPTClient Class**:

```python
class ChatGPTClient:
    def __init__(self, api_key, model):
        self.client = OpenAI(api_key)
        self.model = model
        self.conversation_history = []
        self.system_message = "..."

    def send_message(self, user_message, temperature, max_tokens):
        # Build messages list (system + history + current)
        # Call OpenAI API
        # Update conversation_history
        # Return (response, success)

    def clear_history(self):
        # Reset conversation_history

    def add_system_message(self, message):
        # Update system_message

    def export_conversation(self, filepath):
        # Save to JSON
```

**Interface Compatibility**:

The ChatGPTClient matches App4's expected LLM client interface:

```python
# App4 expects:
response, success = llm_client.send_message(msg, temp, max_tokens)
llm_client.clear_history()
llm_client.add_system_message(prompt)
llm_client.export_conversation(path)

# ChatGPTClient provides exactly this!
```

---

### 3. App4 Components (Imported)

#### From deployment/app4_unified_dashboard/

**core/pipeline_orchestrator.py**:
- Orchestrates 3-stage pipeline
- Manages conversations
- `start_new_conversation()`, `end_conversation()`
- `add_turn()` â†’ Stage 1
- `calculate_stage2_rho()` â†’ Stage 2
- `calculate_stage3_phi()` â†’ Stage 3

**ui/chat_view.py**:
- `create_chat_view()` â†’ ChatView instance
- `render_chat_history()` â†’ Shows messages
- `render_input_area()` â†’ Chat input box
- `render_live_metrics()` â†’ R, v, a, L cards
- `render_live_visualization()` â†’ 4-panel plot
- `render_conversation_controls()` â†’ Start/End/Export buttons

**ui/sidebar.py**:
- `create_sidebar()` â†’ Sidebar instance
- `render()` â†’ Returns config dict
- Model selection, VSAFE config, algorithm weights, etc.

**app.py Tab Renderers**:
- `render_tab1_live_chat()` â†’ Chat + real-time metrics
- `render_tab2_rho_analysis()` â†’ Conversation selector + RHO plots
- `render_tab3_phi_benchmark()` â†’ Multi-conversation PHI analysis
- `render_tab4_settings()` â†’ Session info + configuration

#### From deployment/shared/

**pca_pipeline.py**:
- `PCATransformer` class
- `text_to_2d(text)` â†’ Converts text to 2D vector via embeddings + PCA

**vector_processor.py**:
- `VectorPrecognitionProcessor` class (Stage 1)
- Calculates R, v, a, z, L for each turn

**robustness_calculator.py**:
- `RobustnessCalculator` class (Stage 2)
- Calculates RHO from conversation metrics

**fragility_calculator.py**:
- `FragilityCalculator` class (Stage 3)
- Calculates PHI from multiple RHO values

**visualizations.py**:
- `GuardrailVisualizer`, `RHOVisualizer`, `PHIVisualizer`
- Matplotlib plotting functions

---

## Data Flow

### Conversation Turn Flow

```
1. User types message in Tab 1 chat input
   â†“
2. Streamlit detects input via st.chat_input()
   â†“
3. app.py adds message to SessionState
   â†“
4. PCATransformer.text_to_2d(user_message)
   â†’ Calls AWS Bedrock for embedding
   â†’ Applies PCA to get 2D vector
   â†“
5. ChatGPTClient.send_message(user_message, temp, max_tokens)
   â†’ Calls OpenAI API
   â†’ Returns assistant response
   â†“
6. app.py adds response to SessionState
   â†“
7. PCATransformer.text_to_2d(assistant_message)
   â†’ Get assistant 2D vector
   â†“
8. orchestrator.add_turn(user_msg, asst_msg, user_vec, asst_vec)
   â†’ VectorProcessor calculates R, v, a, z, L
   â†’ Stores in conversation metrics
   â†“
9. st.rerun() â†’ UI updates with new metrics
   â†“
10. ChatView renders updated chat + metrics
```

### RHO Calculation Flow

```
1. User clicks "End Conversation" in Tab 1
   â†“
2. orchestrator.end_conversation()
   â†’ Marks conversation as completed
   â†’ Stores in conversation_history
   â†“
3. User navigates to Tab 2 (RHO Analysis)
   â†“
4. render_tab2_rho_analysis() displays conversation selector
   â†“
5. User selects conversation from dropdown
   â†“
6. Check if stage2_result exists
   â†“ (if not calculated)
7. orchestrator.calculate_stage2_rho()
   â†’ RobustnessCalculator processes metrics
   â†’ Calculates final RHO
   â†’ Classification (ROBUST/REACTIVE/FRAGILE)
   â†“
8. RHOVisualizer creates plots:
   - Cumulative risk (user vs model)
   - RHO timeline
   â†“
9. Display results + plots
```

### PHI Aggregation Flow

```
1. User completes multiple conversations
   â†“
2. Each conversation has RHO calculated (Tab 2)
   â†“
3. User navigates to Tab 3 (PHI Benchmark)
   â†“
4. render_tab3_phi_benchmark() filters conversations with RHO
   â†“
5. orchestrator.calculate_stage3_phi(model_name)
   â†’ FragilityCalculator aggregates RHO values
   â†’ PHI = (1/N) * sum(max(0, rho - 1))
   â†’ Classification (PASS if PHI < 0.1, else FAIL)
   â†“
6. PHIVisualizer creates fragility distribution histogram
   â†“
7. Display breakdown table + PHI score + plot
```

---

## Security Model

### Electron Security

1. **Context Isolation**: Enabled in BrowserWindow
   - Renderer can't access Node.js directly
   - Only preload script has access

2. **Node Integration**: Disabled
   - Renderer runs as regular web page
   - No require() or process access

3. **Web Security**: Enabled
   - CORS, CSP enforced

4. **Preload Script**: Whitelist-only API
   - Only exposes specific IPC handlers
   - No arbitrary code execution

### API Key Storage

1. **electron-store**: AES encryption
2. **Encryption key**: Hardcoded in main.js (should be per-user in production)
3. **Storage location**:
   - Windows: `%APPDATA%/vector-precognition-app4`
   - macOS: `~/Library/Application Support/vector-precognition-app4`
   - Linux: `~/.config/vector-precognition-app4`

4. **Transmission**: Environment variables only
   - Never sent over network (except to OpenAI API)
   - Never logged

### Best Practices

- âœ… API keys encrypted at rest
- âœ… Context isolation prevents XSS
- âœ… No remote code execution
- âœ… HTTPS-only for OpenAI API
- âš ï¸ Encryption key should be per-user (improvement needed)

---

## Performance Considerations

### Bottlenecks

1. **Streamlit Startup**: 10-30 seconds first launch
   - Solution: Show loading screen in Electron
   - Future: Bundle Streamlit with pyinstaller

2. **PCA Transformation**: 2-3 seconds per message
   - Calls AWS Bedrock for embedding (network latency)
   - Solution: Cache embeddings, use local models

3. **Electron Bundle Size**: ~200MB
   - Includes Chromium + Node.js
   - Solution: Use electron-builder compression

4. **Streamlit Reruns**: Full page refresh on interaction
   - Inherent to Streamlit architecture
   - Solution: Use st.experimental_fragment for partial updates

### Optimizations

1. **Lazy Imports**: Only import App4 modules when needed
2. **Session State**: Cache PCA transformer, orchestrator
3. **Matplotlib**: Use st.pyplot(fig, clear_figure=True) to prevent memory leaks
4. **IPC**: Batch multiple operations where possible

---

## Testing Strategy

### Unit Tests

- chatgpt_integration.py: Mock OpenAI API
- Pipeline components: Use App4's existing tests

### Integration Tests

1. **Electron â†” Python**: Test IPC handlers
2. **ChatGPT â†” App4**: Test interface compatibility
3. **End-to-end**: Full conversation flow

### Manual Testing Checklist

- [ ] API key storage/retrieval
- [ ] Conversation with ChatGPT
- [ ] Metrics calculation (R, v, a, L)
- [ ] RHO analysis
- [ ] PHI benchmark
- [ ] Export functionality
- [ ] Mock mode
- [ ] Installer build

---

## Deployment

### Development

```bash
# Python only (browser mode)
cd python-backend
streamlit run app.py

# Electron wrapper
cd electron
npm run dev  # Opens with DevTools
```

### Production

```bash
# Build installers
cd electron
npm run build:win   # Windows NSIS
npm run build:mac   # macOS DMG
npm run build:linux # AppImage + deb
```

### Distribution

Installers include:
- Electron binary
- Python backend (all .py files)
- Node modules
- Not included: Python interpreter (user must have Python)

Future: Bundle Python with pyinstaller for true single-exe distribution.

---

## Extension Points

### Adding New LLM Providers

1. Create new client in `python-backend/`:
   ```python
   class AnthropicClient:
       def send_message(self, msg, temp, max_tokens):
           # Match interface
   ```

2. Update `initialize_app()` to select client based on config

3. Add IPC handlers for new provider's API keys

### Adding New Tabs

1. Create renderer in App4 or desktop-app2:
   ```python
   def render_tab5_custom(config, orchestrator):
       st.header("Custom Tab")
       # Your code
   ```

2. Add tab in main():
   ```python
   tab5 = st.tabs([..., "ðŸ”§ Custom"])
   with tab5:
       render_tab5_custom(...)
   ```

### Customizing Visualizations

Modify `deployment/shared/visualizations.py` or create desktop-app2 specific versions.

---

## Known Limitations

1. **Python required**: User must have Python installed (can't bundle yet)
2. **Single instance**: Only one conversation at a time
3. **No offline mode**: Requires internet for embeddings + ChatGPT
4. **WSL limitations**: Needs X server for GUI

---

**Version**: 2.0.0
**Last Updated**: December 11, 2024
**Maintainer**: Optica Labs
